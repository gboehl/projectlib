{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HANK estimation including household parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook replicates the estimation of the medium-scale HANK model from [Ensemble MCMC Sampling for DSGE Models](https://gregorboehl.com/live/dime_mcmc_boehl.pdf). This is the estimation with the smaller grid, but the estimation of the model with the larger grid is exactly the same. Please refer to the original paper for details.\n",
    "\n",
    "Let's start with a few imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import pathos\n",
    "import emcee\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import emcwrap as ew\n",
    "import grgrlib.hanktools as gsj\n",
    "\n",
    "#from grgrlib import *\n",
    "\n",
    "# set random seed\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the model and get estimation infos from the yaml file. Everything is placed in the ``ressources`` folder relative to this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import model and model infos\n",
    "model = gsj.load_model('ressources/hank2_small.py')\n",
    "est_info = ew.parse_yaml('ressources/hank2.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# load data\n",
    "d0 = pd.read_csv('ressources/BS_data.csv',\n",
    "                 sep=';', index_col='date', parse_dates=True).dropna()\n",
    "d0.index = pd.date_range('1973Q1', periods=len(d0.index), freq='Q')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set data\n",
    "series = ['GDP', 'Infl', 'FFR', 'Cons_JPT', 'Lab', 'Inv_JPT', 'Wage']\n",
    "data = d0[series]['1983Q1':'2008Q4']\n",
    "data = data.to_numpy()\n",
    "# data = data.join(d1[['top10income', 'top10wealth']]['1983Q1':'2008Q4']).to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial SS took 2.2782814502716064s.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# calculate inital steady state\n",
    "st = time.time()\n",
    "hank_ss, ss, unknowns_ss, targets_ss, hank, unknowns, targets, exogenous = model.dag()\n",
    "print('Initial SS took %ss.' % (time.time() - st))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Jacobian took 4.85834527015686s.\n"
     ]
    }
   ],
   "source": [
    "# general equilibrium jacobians\n",
    "st = time.time()\n",
    "G = hank.solve_jacobian(ss, unknowns, targets, exogenous, T=300)\n",
    "print('Initial Jacobian took %ss.' % (time.time() - st))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set measurement errors\n",
    "me_sig = np.std(data, axis=0)*1e-1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   adding Z_AR_COEF...\n",
      "   adding rstar_AR_COEF...\n",
      "   adding G_AR_COEF...\n",
      "   adding markup_w_AR_COEF...\n",
      "   adding markup_AR_COEF...\n",
      "   adding rinv_shock_AR_COEF...\n",
      "   adding beta_AR_COEF...\n",
      "   adding Z_SIG_COEF...\n",
      "   adding rstar_SIG_COEF...\n",
      "   adding G_SIG_COEF...\n",
      "   adding markup_w_SIG_COEF...\n",
      "   adding markup_SIG_COEF...\n",
      "   adding rinv_shock_SIG_COEF...\n",
      "   adding beta_SIG_COEF...\n",
      "Adding parameters to the prior distribution...\n",
      "   - sig_c as normal with mean 1.5 and std/df 0.375\n",
      "   - sig_l as normal with mean 2.0 and std/df 0.75\n",
      "   - chi0 as gamma with mean 0.2 and std/df 0.15\n",
      "   - tau as beta with mean 0.2 and std/df 0.1\n",
      "   - sigma_z as normal with mean 1.0 and std/df 0.4\n",
      "   - phiss as gamma with mean 4.0 and std/df 2.0\n",
      "   - zeta_p as beta with mean 0.5 and std/df 0.1\n",
      "   - zeta_w as beta with mean 0.5 and std/df 0.1\n",
      "   - iota_p as beta with mean 0.5 and std/df 0.15\n",
      "   - iota_w as beta with mean 0.5 and std/df 0.15\n",
      "   - phi_pi as gamma with mean 1.5 and std/df 0.25\n",
      "   - phi_y as gamma with mean 0.125 and std/df 0.05\n",
      "   - rho as beta with mean 0.75 and std/df 0.1\n",
      "   - ybar as normal with mean 0.4 and std/df 0.1\n",
      "   - nbar as normal with mean 0.0 and std/df 2.0\n",
      "   - pistar as gamma with mean 0.625 and std/df 0.1\n",
      "   - rstar as gamma with mean 1.25 and std/df 0.1\n",
      "   - Z_AR_COEF as beta with mean 0.5 and std/df 0.2\n",
      "   - rstar_AR_COEF as beta with mean 0.5 and std/df 0.2\n",
      "   - G_AR_COEF as beta with mean 0.5 and std/df 0.2\n",
      "   - markup_w_AR_COEF as beta with mean 0.5 and std/df 0.2\n",
      "   - markup_AR_COEF as beta with mean 0.5 and std/df 0.2\n",
      "   - rinv_shock_AR_COEF as beta with mean 0.5 and std/df 0.2\n",
      "   - beta_AR_COEF as beta with mean 0.5 and std/df 0.2\n",
      "   - Z_SIG_COEF as inv_gamma with mean 0.1 and std/df 0.25\n",
      "   - rstar_SIG_COEF as inv_gamma with mean 0.1 and std/df 0.25\n",
      "   - G_SIG_COEF as inv_gamma with mean 0.1 and std/df 0.25\n",
      "   - markup_w_SIG_COEF as inv_gamma with mean 0.1 and std/df 0.25\n",
      "   - markup_SIG_COEF as inv_gamma with mean 0.1 and std/df 0.25\n",
      "   - rinv_shock_SIG_COEF as inv_gamma with mean 0.1 and std/df 0.25\n",
      "   - beta_SIG_COEF as inv_gamma with mean 0.1 and std/df 0.25\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# get priors from the yaml\n",
    "prior = est_info['estimation']['prior']\n",
    "shocks = est_info['declarations']['shocks']\n",
    "observables = est_info['declarations']['observables']\n",
    "\n",
    "# compile priors\n",
    "frozen_prior, prior_func, bptrans, _, _, prior = gsj.get_prior(prior, shocks, verbose=True)\n",
    "\n",
    "# Compute jacobian of household block\n",
    "jac_info = {'unknowns': unknowns, 'targets': targets,\n",
    "            'exogenous': exogenous, 'T': 300, 'ss': ss}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def data_func(x, ss, data):\n",
    "    # Remove intercept from series\n",
    "\n",
    "    data_adj = np.empty_like(data)\n",
    "    data_adj[:, 0] = data[:, 0] - ss['ybar']  # y\n",
    "    data_adj[:, 1] = data[:, 1] - ss['pistar']  # pi\n",
    "    data_adj[:, 2] = data[:, 2] - ss['rstar']  # i\n",
    "    data_adj[:, 3] = data[:, 3] - ss['ybar']  # c\n",
    "    data_adj[:, 4] = data[:, 4] - ss['n_obs']  # n\n",
    "    data_adj[:, 5] = data[:, 5] - ss['ybar']  # I\n",
    "    data_adj[:, 6] = data[:, 6] - ss['ybar']  # w\n",
    "    # data_adj[:, 7] = data[:, 7] - ss['top10y_obs']  # w\n",
    "    # data_adj[:, 8] = data[:, 8] - ss['top10w_obs']  # w\n",
    "\n",
    "    return data_adj\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def ss_func(ss, x):\n",
    "\n",
    "    ss['pi'] = ss['pistar']/100\n",
    "    ss['i'] = ss['rstar']/100\n",
    "    ss['r'] = (1 + ss['i']) / (1 + ss['pi']) - 1\n",
    "\n",
    "    # the actual function to calculate the steady state\n",
    "    ss = hank_ss.solve_steady_state(ss, unknowns_ss, targets_ss, solver=\"hybr\")\n",
    "    ss = hank.steady_state(ss)\n",
    "\n",
    "    return ss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def log_ll(x):\n",
    "\n",
    "    # a single likelihood evaluation\n",
    "    x = bptrans(x)\n",
    "    x = np.array(x)\n",
    "\n",
    "    # check prior first, and exit already if infinity\n",
    "    lprior = prior_func(x)\n",
    "    if np.isinf(lprior):\n",
    "        return -np.inf\n",
    "\n",
    "    st = time.time()\n",
    "    # calculate likelihood\n",
    "    llike, ss_local = gsj.get_ll(x, hank, data, data_func, me_sig, jac_info, list(prior), observables, shocks, ss_func=lambda ss, x: ss_func(ss, x), debug=False)\n",
    "\n",
    "    # store relevant steady state values as initial guess\n",
    "    if ss_local is None:\n",
    "        return -np.inf\n",
    "\n",
    "    # print(llike + lprior, np.round(- st + time.time(),5))\n",
    "\n",
    "    return llike + lprior\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO put all parameters at same place\n",
    "# set some parameters\n",
    "ncores = pathos.helpers.cpu_count()\n",
    "nchain = ncores*4\n",
    "nsteps = 2000\n",
    "\n",
    "move = ew.DIMEMove(aimh_prob=0.1)\n",
    "backend_name = '/home/gboehl/npz/hank_small1.h5'\n",
    "\n",
    "backend = emcee.backends.HDFBackend(backend_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [01:32<00:00,  2.90s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(prior_sample:) Sampling done. Check fails for 27.27% of the prior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/2000 [00:00<?, ?sample(s)/s]"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "It is unadvisable to use a red-blue move with fewer walkers than twice the number of dimensions.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [24], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m p0pspace \u001b[38;5;241m=\u001b[39m bptrans(p0, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# sample the sampler\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m sampler \u001b[38;5;241m=\u001b[39m \u001b[43mew\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_mcmc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlog_ll\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp0\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mp0pspace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnsteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnsteps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmoves\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmove\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtune\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m500\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpriors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprior\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprior_transform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbptrans\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbackend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbackend\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mupdate_freq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpool\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpool\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmaintenance_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# old_chain = backend.get_chain()\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# sampler = ew.run_mcmc(log_ll, p0=None, nsteps=nsteps-old_chain.shape[0], moves=move, tune=500, priors=prior, backend=backend, update_freq=100, pool=pool, maintenance_interval=10, resume=True)\u001b[39;00m\n\u001b[1;32m     14\u001b[0m ew\u001b[38;5;241m.\u001b[39msave_to_backend(sampler, {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtune\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m500\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpriors\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mlist\u001b[39m(prior)})\n",
      "File \u001b[0;32m~/github/emcwrap/emcwrap/sampler.py:48\u001b[0m, in \u001b[0;36mrun_mcmc\u001b[0;34m(lprob, nsteps, p0, moves, stopping_weight, priors, prior_transform, backend, update_freq, resume, pool, report, description, temp, maintenance_interval, verbose, **kwargs)\u001b[0m\n\u001b[1;32m     45\u001b[0m cumlweight \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39mnp\u001b[38;5;241m.\u001b[39minf\n\u001b[1;32m     46\u001b[0m cnt \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m---> 48\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m result \u001b[38;5;129;01min\u001b[39;00m sampler\u001b[38;5;241m.\u001b[39msample(p0, iterations\u001b[38;5;241m=\u001b[39mnsteps, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stopping_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         state_weight \u001b[38;5;241m=\u001b[39m cumlweight \u001b[38;5;241m-\u001b[39m moves\u001b[38;5;241m.\u001b[39mcumlweight\n",
      "File \u001b[0;32m/usr/lib/python3.10/site-packages/emcee/ensemble.py:402\u001b[0m, in \u001b[0;36mEnsembleSampler.sample\u001b[0;34m(self, initial_state, log_prob0, rstate0, blobs0, iterations, tune, skip_initial_state_check, thin_by, thin, store, progress, progress_kwargs)\u001b[0m\n\u001b[1;32m    399\u001b[0m move \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_random\u001b[38;5;241m.\u001b[39mchoice(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_moves, p\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_weights)\n\u001b[1;32m    401\u001b[0m \u001b[38;5;66;03m# Propose\u001b[39;00m\n\u001b[0;32m--> 402\u001b[0m state, accepted \u001b[38;5;241m=\u001b[39m \u001b[43mmove\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpropose\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    403\u001b[0m state\u001b[38;5;241m.\u001b[39mrandom_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrandom_state\n\u001b[1;32m    405\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tune:\n",
      "File \u001b[0;32m~/github/emcwrap/emcwrap/moves.py:79\u001b[0m, in \u001b[0;36mDIMEMove.propose\u001b[0;34m(self, model, state)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;124;03m\"\"\"Wrap original propose to get the some info on the current state\u001b[39;00m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlprobs \u001b[38;5;241m=\u001b[39m state\u001b[38;5;241m.\u001b[39mlog_prob\n\u001b[0;32m---> 79\u001b[0m state, accepted \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mDIMEMove\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpropose\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccepted \u001b[38;5;241m=\u001b[39m accepted\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m state, accepted\n",
      "File \u001b[0;32m/usr/lib/python3.10/site-packages/emcee/moves/red_blue.py:66\u001b[0m, in \u001b[0;36mRedBlueMove.propose\u001b[0;34m(self, model, state)\u001b[0m\n\u001b[1;32m     64\u001b[0m nwalkers, ndim \u001b[38;5;241m=\u001b[39m state\u001b[38;5;241m.\u001b[39mcoords\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m nwalkers \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m ndim \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlive_dangerously:\n\u001b[0;32m---> 66\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m     67\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt is unadvisable to use a red-blue move \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     68\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwith fewer walkers than twice the number of \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     69\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdimensions.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     70\u001b[0m     )\n\u001b[1;32m     72\u001b[0m \u001b[38;5;66;03m# Run any move-specific setup.\u001b[39;00m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msetup(state\u001b[38;5;241m.\u001b[39mcoords)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: It is unadvisable to use a red-blue move with fewer walkers than twice the number of dimensions."
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "pool = pathos.pools.ProcessPool()\n",
    "\n",
    "# get a prior sample\n",
    "p0 = ew.get_prior_sample(frozen_prior, nchain, mapper=pool.uimap, check_func=lambda x: log_ll(bptrans(x, False)), debug=False)\n",
    "p0pspace = bptrans(p0, False)\n",
    "\n",
    "# sample the sampler\n",
    "sampler = ew.run_mcmc(log_ll, p0=p0pspace, nsteps=nsteps, moves=move, tune=500, priors=prior, prior_transform=bptrans, backend=backend, update_freq=100, pool=pool, maintenance_interval=10)\n",
    "\n",
    "# old_chain = backend.get_chain()\n",
    "# sampler = ew.run_mcmc(log_ll, p0=None, nsteps=nsteps-old_chain.shape[0], moves=move, tune=500, priors=prior, backend=backend, update_freq=100, pool=pool, maintenance_interval=10, resume=True)\n",
    "\n",
    "ew.save_to_backend(sampler, {'tune': 500, 'priors': list(prior)})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
